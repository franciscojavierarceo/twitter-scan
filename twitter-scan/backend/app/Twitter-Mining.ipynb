{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "amateur-dining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/site-packages (3.10.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/site-packages (from tweepy) (2.25.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/site-packages (from tweepy) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (1.26.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.20.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (1.2.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torch) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch) (3.7.4.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tweepy\n",
    "! pip install numpy\n",
    "! pip install pandas\n",
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "robust-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting detoxify\n",
      "  Using cached detoxify-0.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting sentencepiece>=0.1.94\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 410 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch>=1.7.0\n",
      "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 804.1 MB 2.4 kB/s eta 0:00:01    |█                               | 22.7 MB 1.7 MB/s eta 0:07:38     |██▎                             | 56.1 MB 2.1 MB/s eta 0:05:57     |███▏                            | 78.4 MB 2.1 MB/s eta 0:05:51     |████████▊                       | 220.1 MB 2.5 MB/s eta 0:03:53     |██████████                      | 249.1 MB 2.5 MB/s eta 0:03:39     |███████████▉                    | 297.1 MB 2.4 MB/s eta 0:03:31     |█████████████                   | 326.2 MB 2.0 MB/s eta 0:03:58     |█████████████▊                  | 343.8 MB 2.6 MB/s eta 0:02:59     |███████████████▍                | 386.7 MB 2.5 MB/s eta 0:02:45     |████████████████▍               | 411.5 MB 1.9 MB/s eta 0:03:23     |███████████████████▎            | 485.7 MB 2.3 MB/s eta 0:02:19     |█████████████████████▏          | 531.5 MB 1.8 MB/s eta 0:02:28     |██████████████████████▍         | 562.8 MB 1.9 MB/s eta 0:02:09     |███████████████████████▏        | 583.3 MB 2.6 MB/s eta 0:01:27     |████████████████████████        | 605.7 MB 1.9 MB/s eta 0:01:47     |████████████████████████▍       | 611.9 MB 1.9 MB/s eta 0:01:43     |█████████████████████████████▍  | 737.7 MB 2.9 MB/s eta 0:00:24     |██████████████████████████████▎ | 760.2 MB 2.1 MB/s eta 0:00:22\n",
      "\u001b[?25hCollecting transformers>=3.2.0\n",
      "  Downloading transformers-4.4.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 430 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torch>=1.7.0->detoxify) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch>=1.7.0->detoxify) (3.7.4.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from transformers>=3.2.0->detoxify) (20.9)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 439 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from transformers>=3.2.0->detoxify) (3.7.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from transformers>=3.2.0->detoxify) (2.25.1)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/site-packages (from transformers>=3.2.0->detoxify) (2021.3.17)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->transformers>=3.2.0->detoxify) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from sacremoses->transformers>=3.2.0->detoxify) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/site-packages (from sacremoses->transformers>=3.2.0->detoxify) (7.1.2)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=3.2.0->detoxify) (3.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->transformers>=3.2.0->detoxify) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->transformers>=3.2.0->detoxify) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->transformers>=3.2.0->detoxify) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->transformers>=3.2.0->detoxify) (2020.12.5)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=9b890b0709b722b28102c785f25bc25648e2060cca96e3deb444be1523ec5dee\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, torch, joblib, tqdm, sacremoses, tokenizers, filelock, transformers, detoxify\n",
      "Successfully installed detoxify-0.2.2 filelock-3.0.12 joblib-1.0.1 sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.10.1 torch-1.8.1 tqdm-4.59.0 transformers-4.4.2\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install detoxify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "intimate-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "artificial-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detoxify import Detoxify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "conceptual-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER_API_KEY = os.environ.get('TWITTER_API_KEY')\n",
    "TWITTER_API_SECRET = os.environ.get('TWITTER_API_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "muslim-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(TWITTER_API_KEY, TWITTER_API_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unlimited-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "changed-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = api.get_user('franciscojarceo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tough-joseph",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Francisco Javier Arceo'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp._json['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brutal-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []  \n",
    "\n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name, count=200)\n",
    "\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(f\"getting tweets before {oldest}\")\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200, max_id=oldest)\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "\n",
    "    return alltweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dynamic-husband",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1370572974085058559\n",
      "...396 tweets downloaded so far\n",
      "getting tweets before 1366097134504796163\n",
      "...596 tweets downloaded so far\n",
      "getting tweets before 1362465423136972800\n",
      "...795 tweets downloaded so far\n",
      "getting tweets before 1359208814202019841\n",
      "...994 tweets downloaded so far\n",
      "getting tweets before 1356630343391002623\n",
      "...1193 tweets downloaded so far\n",
      "getting tweets before 1354471901167554566\n",
      "...1393 tweets downloaded so far\n",
      "getting tweets before 1352590445164027906\n",
      "...1592 tweets downloaded so far\n",
      "getting tweets before 1351252276078374911\n",
      "...1791 tweets downloaded so far\n",
      "getting tweets before 1349203559301193727\n",
      "...1990 tweets downloaded so far\n",
      "getting tweets before 1347691286174822402\n",
      "...2189 tweets downloaded so far\n",
      "getting tweets before 1345232393666490368\n",
      "...2389 tweets downloaded so far\n",
      "getting tweets before 1342152007289774080\n",
      "...2589 tweets downloaded so far\n",
      "getting tweets before 1340520723949842436\n",
      "...2789 tweets downloaded so far\n",
      "getting tweets before 1338632496678768639\n",
      "...2989 tweets downloaded so far\n",
      "getting tweets before 1335615033217220607\n",
      "...3189 tweets downloaded so far\n",
      "getting tweets before 1333396868982738944\n",
      "...3237 tweets downloaded so far\n",
      "getting tweets before 1332489376530460671\n",
      "...3237 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "mytweets = get_all_tweets('franciscojarceo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "original-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytweets[2]._json['in_reply_to_status_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "saving-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytweets[1]._json['in_reply_to_status_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "analyzed-diagram",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1378724057357578243"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytweets[1]._json['id'] #['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cosmetic-oakland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'in_reply_to_status_id' in mytweets[1]._json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "patient-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(x):\n",
    "    try:\n",
    "        clean = re.sub(\"@[A-Za-z0-9_]+\",\"\", x).strip()\n",
    "        replytweet = re.match('… https://t.co/*', clean)\n",
    "        if replytweet is not None:\n",
    "            if replytweet.end() > 0:\n",
    "                return None\n",
    "        return clean\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "searching-privilege",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 4s, sys: 1min 3s, total: 31min 7s\n",
      "Wall time: 56min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dv = -1.0\n",
    "dvd = {\n",
    "    'toxicity': dv,\n",
    "    'severe_toxicity': dv,\n",
    "    'obscene': dv,\n",
    "    'threat': dv,\n",
    "    'insult': dv,\n",
    "    'identity_hate': dv\n",
    "}\n",
    "\n",
    "res = []\n",
    "tweeters = []\n",
    "preds = []\n",
    "for i in mytweets:\n",
    "    if i._json['in_reply_to_status_id'] is not None:\n",
    "        cleaned = clean_tweet(i._json['text'])\n",
    "        res.append((i._json['id'], i._json['text'], cleaned))\n",
    "        prediction = [dvd if cleaned is None else Detoxify('original').predict(cleaned)]\n",
    "        tweeters.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "disabled-affair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions2['toxicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "extended-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in mytweets:\n",
    "    if i._json['in_reply_to_status_id'] is not None:\n",
    "        cleaned = clean_tweet(i._json['text'])\n",
    "        res.append((i._json['id'], i._json['text'], cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "timely-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame(res, columns=['tweet_id', 'tweet', 'cleaned_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "micro-dylan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 59s, sys: 10.4 s, total: 3min 10s\n",
      "Wall time: 53.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions2 = Detoxify('original').predict(cdf[cdf['cleaned_tweet'].isnull()==False]['cleaned_tweet'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "exempt-morning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=797, step=1)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdfp.reset_index(drop=True).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfp = pd.concat([pd.DataFrame(t) for t in tweeters], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dramatic-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "integrated-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame(res, columns=['tweet_id', 'tweet'])\n",
    "tdfp = pd.concat([pd.DataFrame(t) for t in tweeters], axis=0).reset_index(drop=True)\n",
    "xvars = [\n",
    "    'toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult','identity_hate'\n",
    "]\n",
    "for x in xvars:\n",
    "    tdf[x] = tdfp[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "signed-going",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((797, 8), (797, 6))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.shape, tdfp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "legitimate-revision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1378516199642779650</td>\n",
       "      <td>@IsaiBCortez @cisco_iz @Eliana_Murillo @Buildw...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1378511218994868228</td>\n",
       "      <td>@BuildwithJoy @Eliana_Murillo @EuniceCancino @...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1378509699104927744</td>\n",
       "      <td>@BuildwithJoy @Eliana_Murillo @EuniceCancino @...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1378509579860930560</td>\n",
       "      <td>@tsawruk Chinese BBQ pork!!! Wife made this to...</td>\n",
       "      <td>0.252908</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.013218</td>\n",
       "      <td>0.012737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1378508719349112832</td>\n",
       "      <td>@Eliana_Murillo @BuildwithJoy @EuniceCancino @...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1378516199642779650  @IsaiBCortez @cisco_iz @Eliana_Murillo @Buildw...   \n",
       "1  1378511218994868228  @BuildwithJoy @Eliana_Murillo @EuniceCancino @...   \n",
       "2  1378509699104927744  @BuildwithJoy @Eliana_Murillo @EuniceCancino @...   \n",
       "3  1378509579860930560  @tsawruk Chinese BBQ pork!!! Wife made this to...   \n",
       "4  1378508719349112832  @Eliana_Murillo @BuildwithJoy @EuniceCancino @...   \n",
       "\n",
       "   toxicity  severe_toxicity   obscene    threat    insult  identity_hate  \n",
       "0 -1.000000        -1.000000 -1.000000 -1.000000 -1.000000      -1.000000  \n",
       "1 -1.000000        -1.000000 -1.000000 -1.000000 -1.000000      -1.000000  \n",
       "2 -1.000000        -1.000000 -1.000000 -1.000000 -1.000000      -1.000000  \n",
       "3  0.252908         0.000787  0.012521  0.001147  0.013218       0.012737  \n",
       "4 -1.000000        -1.000000 -1.000000 -1.000000 -1.000000      -1.000000  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "common-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['risk'] = tdf[xvars].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "known-technology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    797.000000\n",
       "mean      -0.040707\n",
       "std        0.271744\n",
       "min       -1.000000\n",
       "25%        0.000711\n",
       "50%        0.001126\n",
       "75%        0.003694\n",
       "max        0.919482\n",
       "Name: risk, dtype: float64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf['risk'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "covered-percentage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1358441959384354816</td>\n",
       "      <td>@IsaiBCortez Heck yeah, bro.\\n\\nThank God ever...</td>\n",
       "      <td>0.919482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>1341018195709161473</td>\n",
       "      <td>@paul__132 Most code comments and documentatio...</td>\n",
       "      <td>0.892314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>1334353023678574592</td>\n",
       "      <td>@MilesNextDoor bro u don't know how much i suc...</td>\n",
       "      <td>0.870974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>1335728924018425856</td>\n",
       "      <td>@chachovaladez Die Hard.\\n\\nJust kidding, it’s...</td>\n",
       "      <td>0.847634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>1335019222057897984</td>\n",
       "      <td>@mikulaja Also, that boss was obviously a jerk...</td>\n",
       "      <td>0.811857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1363085498164514818</td>\n",
       "      <td>@estebanuribe @EuniceCancino @Eliana_Murillo @...</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1363085233944363008</td>\n",
       "      <td>@EuniceCancino @Eliana_Murillo @estebanuribe @...</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1362967936508387332</td>\n",
       "      <td>@EuniceCancino @Eliana_Murillo @estebanuribe @...</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1362965700701167617</td>\n",
       "      <td>@Eliana_Murillo @estebanuribe @EuniceCancino @...</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1378516199642779650</td>\n",
       "      <td>@IsaiBCortez @cisco_iz @Eliana_Murillo @Buildw...</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>797 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                              tweet  \\\n",
       "270  1358441959384354816  @IsaiBCortez Heck yeah, bro.\\n\\nThank God ever...   \n",
       "658  1341018195709161473  @paul__132 Most code comments and documentatio...   \n",
       "753  1334353023678574592  @MilesNextDoor bro u don't know how much i suc...   \n",
       "737  1335728924018425856  @chachovaladez Die Hard.\\n\\nJust kidding, it’s...   \n",
       "745  1335019222057897984  @mikulaja Also, that boss was obviously a jerk...   \n",
       "..                   ...                                                ...   \n",
       "172  1363085498164514818  @estebanuribe @EuniceCancino @Eliana_Murillo @...   \n",
       "173  1363085233944363008  @EuniceCancino @Eliana_Murillo @estebanuribe @...   \n",
       "174  1362967936508387332  @EuniceCancino @Eliana_Murillo @estebanuribe @...   \n",
       "175  1362965700701167617  @Eliana_Murillo @estebanuribe @EuniceCancino @...   \n",
       "0    1378516199642779650  @IsaiBCortez @cisco_iz @Eliana_Murillo @Buildw...   \n",
       "\n",
       "         risk  \n",
       "270  0.919482  \n",
       "658  0.892314  \n",
       "753  0.870974  \n",
       "737  0.847634  \n",
       "745  0.811857  \n",
       "..        ...  \n",
       "172 -1.000000  \n",
       "173 -1.000000  \n",
       "174 -1.000000  \n",
       "175 -1.000000  \n",
       "0   -1.000000  \n",
       "\n",
       "[797 rows x 3 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.sort_values(by='risk', ascending=False)[['tweet_id', 'tweet', 'risk']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-request",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
