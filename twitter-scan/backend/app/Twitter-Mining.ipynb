{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "supported-madagascar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/site-packages (3.10.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/site-packages (from tweepy) (2.25.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/site-packages (from tweepy) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (1.26.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.20.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (1.2.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torch) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch) (3.7.4.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tweepy\n",
    "! pip install numpy\n",
    "! pip install pandas\n",
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "direct-coffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting detoxify\n",
      "  Using cached detoxify-0.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting sentencepiece>=0.1.94\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 410 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch>=1.7.0\n",
      "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 804.1 MB 2.4 kB/s eta 0:00:01    |█                               | 22.7 MB 1.7 MB/s eta 0:07:38     |██▎                             | 56.1 MB 2.1 MB/s eta 0:05:57     |███▏                            | 78.4 MB 2.1 MB/s eta 0:05:51     |████████▊                       | 220.1 MB 2.5 MB/s eta 0:03:53     |██████████                      | 249.1 MB 2.5 MB/s eta 0:03:39     |███████████▉                    | 297.1 MB 2.4 MB/s eta 0:03:31     |█████████████                   | 326.2 MB 2.0 MB/s eta 0:03:58     |█████████████▊                  | 343.8 MB 2.6 MB/s eta 0:02:59     |███████████████▍                | 386.7 MB 2.5 MB/s eta 0:02:45     |████████████████▍               | 411.5 MB 1.9 MB/s eta 0:03:23     |███████████████████▎            | 485.7 MB 2.3 MB/s eta 0:02:19     |█████████████████████▏          | 531.5 MB 1.8 MB/s eta 0:02:28     |██████████████████████▍         | 562.8 MB 1.9 MB/s eta 0:02:09     |███████████████████████▏        | 583.3 MB 2.6 MB/s eta 0:01:27     |████████████████████████        | 605.7 MB 1.9 MB/s eta 0:01:47     |████████████████████████▍       | 611.9 MB 1.9 MB/s eta 0:01:43     |█████████████████████████████▍  | 737.7 MB 2.9 MB/s eta 0:00:24     |██████████████████████████████▎ | 760.2 MB 2.1 MB/s eta 0:00:22\n",
      "\u001b[?25hCollecting transformers>=3.2.0\n",
      "  Downloading transformers-4.4.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 430 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torch>=1.7.0->detoxify) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch>=1.7.0->detoxify) (3.7.4.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from transformers>=3.2.0->detoxify) (20.9)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 439 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from transformers>=3.2.0->detoxify) (3.7.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from transformers>=3.2.0->detoxify) (2.25.1)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/site-packages (from transformers>=3.2.0->detoxify) (2021.3.17)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->transformers>=3.2.0->detoxify) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from sacremoses->transformers>=3.2.0->detoxify) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/site-packages (from sacremoses->transformers>=3.2.0->detoxify) (7.1.2)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=3.2.0->detoxify) (3.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->transformers>=3.2.0->detoxify) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->transformers>=3.2.0->detoxify) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->transformers>=3.2.0->detoxify) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->transformers>=3.2.0->detoxify) (2020.12.5)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=9b890b0709b722b28102c785f25bc25648e2060cca96e3deb444be1523ec5dee\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, torch, joblib, tqdm, sacremoses, tokenizers, filelock, transformers, detoxify\n",
      "Successfully installed detoxify-0.2.2 filelock-3.0.12 joblib-1.0.1 sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.10.1 torch-1.8.1 tqdm-4.59.0 transformers-4.4.2\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install detoxify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "great-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "instant-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detoxify import Detoxify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "auburn-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER_API_KEY = os.environ.get(\"TWITTER_API_KEY\")\n",
    "TWITTER_API_SECRET = os.environ.get(\"TWITTER_API_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metropolitan-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(TWITTER_API_KEY, TWITTER_API_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "compound-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "military-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = api.get_user(\"franciscojarceo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aboriginal-willow",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Francisco Javier Arceo'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp._json[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thorough-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "    # initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "\n",
    "    # make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name=screen_name, count=200)\n",
    "\n",
    "    # save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    # save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    # keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(f\"getting tweets before {oldest}\")\n",
    "        # all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(\n",
    "            screen_name=screen_name, count=200, max_id=oldest\n",
    "        )\n",
    "        # save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        # update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "\n",
    "    return alltweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "annoying-ceremony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1377375710969393152\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 1372213396498616319\n",
      "...599 tweets downloaded so far\n",
      "getting tweets before 1365805242273591301\n",
      "...799 tweets downloaded so far\n",
      "getting tweets before 1360974738982465535\n",
      "...999 tweets downloaded so far\n",
      "getting tweets before 1357492678255026176\n",
      "...1199 tweets downloaded so far\n",
      "getting tweets before 1354956954217574400\n",
      "...1399 tweets downloaded so far\n",
      "getting tweets before 1352289830047080449\n",
      "...1599 tweets downloaded so far\n",
      "getting tweets before 1345413540874579970\n",
      "...1799 tweets downloaded so far\n",
      "getting tweets before 1340400674329120767\n",
      "...1999 tweets downloaded so far\n",
      "getting tweets before 1336331686619967487\n",
      "...2199 tweets downloaded so far\n",
      "getting tweets before 1333202628096847871\n",
      "...2399 tweets downloaded so far\n",
      "getting tweets before 1330710747354054666\n",
      "...2599 tweets downloaded so far\n",
      "getting tweets before 1328558530916282370\n",
      "...2799 tweets downloaded so far\n",
      "getting tweets before 1325120087678857224\n",
      "...2999 tweets downloaded so far\n",
      "getting tweets before 1321599323424006143\n",
      "...3199 tweets downloaded so far\n",
      "getting tweets before 1316029633096163327\n",
      "...3248 tweets downloaded so far\n",
      "getting tweets before 1314295805730197503\n",
      "...3248 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "sheels = get_all_tweets(\"pitdesi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "meaning-above",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sheels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "sustained-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "sres = []\n",
    "for i in sheels:\n",
    "    cleaned = clean_tweet(i._json[\"text\"])\n",
    "    sres.append((i._json[\"id\"], i._json[\"text\"], cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "isolated-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.DataFrame(sres, columns=[\"tweet_id\", \"tweet\", \"cleaned_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "acknowledged-junction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ParikPatelCFA @TurnerNovak add this tweet to your pitch deck\n",
      "@mikesshapiro They acted on that tweet real fast\n",
      "@ParikPatelCFA @_xbt1 @KarimBhalwani @chamath @SrBachchan I wish I could like this tweet so many more times\n",
      "@twititout 1) I didn't tweet everything the investor said;\n",
      "2) I happen to trust this person a lot\n",
      "How is this not standard practice?\n",
      "\n",
      "If making a high-profile hire: go through every old tweet and Instagram post; i… https://t.co/TTKbt04muu\n",
      "@rkesteva I totally thought someone else would tweet that to me :)\n",
      "wow; @rohamg offered $100k to \"own\" this tweet... \n",
      "Let's see where it ends up.\n",
      "\n",
      "There is a lot of hype for NFT's ri… https://t.co/bD6qabKio5\n",
      "RT @wongmjane: Twitter is working on “Undo Send” timer for tweets https://t.co/nS0kuijPK0\n",
      "@kurtosis0 @koolaid @MrPeanut they are both still tweeting!\n",
      "@howardlindzon I only tweet in the bathroom, but I eat a lot of Indian food so spend a fair amount of time in there.\n",
      "@fintechjunkie @RobinhoodApp Just chanced on this tweet. You were so close, @fintechjunkie !!!\n",
      "@alth0u I feel like some bot could do a pretty good job on this based off of tweets...\n",
      "\n",
      "Indian guy, went to CMU - p… https://t.co/f4YCbn4SPU\n",
      "@arampell ^^^ excellent tweet, embarrassed I didn’t think of that\n",
      "@samcates Good point, though I assume this came about bc Ryan tweeted it out last week so he could have reached out\n",
      "RT @mattturck: VC content marketing, a timeline:\n",
      "\n",
      "* 2000s: blog posts \n",
      "\n",
      "* 2010s: tweets\n",
      "\n",
      "* 2020: memes\n",
      "\n",
      "* 2021: shirtless pics\n",
      "@sheel @arfrank whoa! Your only public tweet!\n",
      "Nice to meet you\n",
      "@terryangelos yup - I heard $700M, he mentioned the final number after i tweeted\n",
      "@lennysan How does this dude @sheel who hasn’t tweeted in 9 years have my name... plz help\n",
      "@immad This is not a real site that he launched... supporters made it for him and I think he tweeted it as a test balloon\n",
      "And yes, this is a subtweet of @TurnerNovak https://t.co/UXExgsKstR\n",
      "@schlaf @emollick the tweet says \"contrary to what most VC's believe...\"\n",
      "\n",
      "most VCs believe that having multiple fou… https://t.co/sg3eL50QeL\n",
      "@robfindlay lol. I didnt realize I was in a ch room until i saw this tweet... must have been an errant touch or something\n",
      "RT @pitdesi: @itskristofer I once tweeted that spaghetti was too long and got tons of hate tweets; someone got so mad that he made an 11 mi…\n",
      "@itskristofer I once tweeted that spaghetti was too long and got tons of hate tweets; someone got so mad that he ma… https://t.co/OGACRioTf1\n",
      "@GritGrowthCap I haven’t been in years but can smell the mushroom compost just reading this tweet. Such a distinct smell\n",
      "@neildugal @SEBillionair Not any that can read this tweet\n",
      "2) Cos trade at different multiples; capital efficiency matters! Related to the prev tweet. \n",
      "\n",
      "Cos 1 and 3 trade at… https://t.co/c9HJjdcyf2\n",
      "Funny tweet about airbnb service fees  and ipo price\n",
      "Gotta look at ALL the insider $SFIX trades to truly understand this tweet https://t.co/vacCLotR3N\n",
      "@ricburton And my typo in the parent tweet. Need an edit button!!!\n",
      "@ericbahn The data suggests otherwise as one of my most engaging tweets was just me saying that I’m staying in SF.… https://t.co/kNaLiM9p1s\n",
      "This is a great set of rules for good business writing. Most of it applies for good tweeting too. https://t.co/wvMrQEGWKx\n",
      "@kduneja Yeah it’s in my tweet!\n",
      "@GottliebShow Here’s the tweet where he posted his highlight reel: https://t.co/4ZBJZhHNmo\n",
      "@caitlinbolnick1 also gotta tweet if you're staying, lest people be unsure\n",
      "My previous tweet suggested that 4 of the 10 were based here but I was using 1-week old data... one of them had a dramatic run this week :)\n",
      "@tweettal Stock market\n",
      "@midtownninja @NYCPai hahah yes, actually that is what i was eating when i tweeted this :)\n",
      "@regulatorynerd @fintechjunkie Excellent tweeting!!!\n",
      "@CNBC whoever is in charge of tweets from @CNBC is a horrible person for not mentioning that the sale was done auto… https://t.co/DHBBDUExOk\n",
      "@micahjay1 Just realizing that I completely misread your initial tweet! I thought you said one *earns* 10x more. that makes complete sense\n",
      "RT @Bob_Wachter: Covid (@UCSF) Chronicles, Day 237\n",
      "\n",
      "Didn't plan to tweet today, but can’t resist a few quick takes on @pfizer vaccine news…\n",
      "I guess everyone else also thought of the “you’re fired” tweet, huh?\n",
      "@lorakolodny @JoshuaOgundu this makes sense; a better tweet from me (and what I actually wanted to articulate) woul… https://t.co/4YWqG6sgpx\n",
      "I had seen maybe 20 tweets referencing this but didn't know where the original came from.\n",
      "\n",
      "If you're on the same pr… https://t.co/ATnfrUXbTl\n"
     ]
    }
   ],
   "source": [
    "for t in sdf[sdf[\"tweet\"].str.contains(\"tweet\")][\"tweet\"]:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unusual-commerce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1370572974085058559\n",
      "...396 tweets downloaded so far\n",
      "getting tweets before 1366097134504796163\n",
      "...596 tweets downloaded so far\n",
      "getting tweets before 1362465423136972800\n",
      "...795 tweets downloaded so far\n",
      "getting tweets before 1359208814202019841\n",
      "...994 tweets downloaded so far\n",
      "getting tweets before 1356630343391002623\n",
      "...1193 tweets downloaded so far\n",
      "getting tweets before 1354471901167554566\n",
      "...1393 tweets downloaded so far\n",
      "getting tweets before 1352590445164027906\n",
      "...1592 tweets downloaded so far\n",
      "getting tweets before 1351252276078374911\n",
      "...1791 tweets downloaded so far\n",
      "getting tweets before 1349203559301193727\n",
      "...1990 tweets downloaded so far\n",
      "getting tweets before 1347691286174822402\n",
      "...2189 tweets downloaded so far\n",
      "getting tweets before 1345232393666490368\n",
      "...2389 tweets downloaded so far\n",
      "getting tweets before 1342152007289774080\n",
      "...2589 tweets downloaded so far\n",
      "getting tweets before 1340520723949842436\n",
      "...2789 tweets downloaded so far\n",
      "getting tweets before 1338632496678768639\n",
      "...2989 tweets downloaded so far\n",
      "getting tweets before 1335615033217220607\n",
      "...3189 tweets downloaded so far\n",
      "getting tweets before 1333396868982738944\n",
      "...3237 tweets downloaded so far\n",
      "getting tweets before 1332489376530460671\n",
      "...3237 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "mytweets = get_all_tweets(\"franciscojarceo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "historical-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytweets[2]._json[\"in_reply_to_status_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "authorized-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytweets[1]._json[\"in_reply_to_status_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "champion-retail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1378724057357578243"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytweets[1]._json[\"id\"]  # ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "human-bankruptcy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"in_reply_to_status_id\" in mytweets[1]._json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "flush-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(x):\n",
    "    try:\n",
    "        clean = re.sub(\"@[A-Za-z0-9_]+\", \"\", x).strip()\n",
    "        replytweet = re.match(\"… https://t.co/*\", clean)\n",
    "        if replytweet is not None:\n",
    "            if replytweet.end() > 0:\n",
    "                return None\n",
    "        return clean\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "wound-anthropology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 4s, sys: 1min 3s, total: 31min 7s\n",
      "Wall time: 56min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dv = -1.0\n",
    "dvd = {\n",
    "    \"toxicity\": dv,\n",
    "    \"severe_toxicity\": dv,\n",
    "    \"obscene\": dv,\n",
    "    \"threat\": dv,\n",
    "    \"insult\": dv,\n",
    "    \"identity_hate\": dv,\n",
    "}\n",
    "\n",
    "res = []\n",
    "tweeters = []\n",
    "preds = []\n",
    "for i in mytweets:\n",
    "    if i._json[\"in_reply_to_status_id\"] is not None:\n",
    "        cleaned = clean_tweet(i._json[\"text\"])\n",
    "        res.append((i._json[\"id\"], i._json[\"text\"], cleaned))\n",
    "        prediction = [dvd if cleaned is None else Detoxify(\"original\").predict(cleaned)]\n",
    "        tweeters.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "stylish-macintosh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions2[\"toxicity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "sporting-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in mytweets:\n",
    "    if i._json[\"in_reply_to_status_id\"] is not None:\n",
    "        cleaned = clean_tweet(i._json[\"text\"])\n",
    "        res.append((i._json[\"id\"], i._json[\"text\"], cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "arbitrary-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame(res, columns=[\"tweet_id\", \"tweet\", \"cleaned_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "later-facial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 59s, sys: 10.4 s, total: 3min 10s\n",
      "Wall time: 53.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions2 = Detoxify(\"original\").predict(\n",
    "    cdf[cdf[\"cleaned_tweet\"].isnull() == False][\"cleaned_tweet\"].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ethical-singing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=797, step=1)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdfp.reset_index(drop=True).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfp = pd.concat([pd.DataFrame(t) for t in tweeters], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "changed-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "obvious-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame(res, columns=[\"tweet_id\", \"tweet\"])\n",
    "tdfp = pd.concat([pd.DataFrame(t) for t in tweeters], axis=0).reset_index(drop=True)\n",
    "xvars = [\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "for x in xvars:\n",
    "    tdf[x] = tdfp[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cellular-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((797, 8), (797, 6))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.shape, tdfp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "adult-disposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1378516199642779650</td>\n",
       "      <td>@IsaiBCortez @cisco_iz @Eliana_Murillo @Buildw...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1378511218994868228</td>\n",
       "      <td>@BuildwithJoy @Eliana_Murillo @EuniceCancino @...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1378509699104927744</td>\n",
       "      <td>@BuildwithJoy @Eliana_Murillo @EuniceCancino @...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1378509579860930560</td>\n",
       "      <td>@tsawruk Chinese BBQ pork!!! Wife made this to...</td>\n",
       "      <td>0.252908</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.013218</td>\n",
       "      <td>0.012737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1378508719349112832</td>\n",
       "      <td>@Eliana_Murillo @BuildwithJoy @EuniceCancino @...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0  1378516199642779650  @IsaiBCortez @cisco_iz @Eliana_Murillo @Buildw...   \n",
       "1  1378511218994868228  @BuildwithJoy @Eliana_Murillo @EuniceCancino @...   \n",
       "2  1378509699104927744  @BuildwithJoy @Eliana_Murillo @EuniceCancino @...   \n",
       "3  1378509579860930560  @tsawruk Chinese BBQ pork!!! Wife made this to...   \n",
       "4  1378508719349112832  @Eliana_Murillo @BuildwithJoy @EuniceCancino @...   \n",
       "\n",
       "   toxicity  severe_toxicity   obscene    threat    insult  identity_hate  \n",
       "0 -1.000000        -1.000000 -1.000000 -1.000000 -1.000000      -1.000000  \n",
       "1 -1.000000        -1.000000 -1.000000 -1.000000 -1.000000      -1.000000  \n",
       "2 -1.000000        -1.000000 -1.000000 -1.000000 -1.000000      -1.000000  \n",
       "3  0.252908         0.000787  0.012521  0.001147  0.013218       0.012737  \n",
       "4 -1.000000        -1.000000 -1.000000 -1.000000 -1.000000      -1.000000  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "adopted-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf[\"risk\"] = tdf[xvars].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "powerful-adolescent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    797.000000\n",
       "mean      -0.040707\n",
       "std        0.271744\n",
       "min       -1.000000\n",
       "25%        0.000711\n",
       "50%        0.001126\n",
       "75%        0.003694\n",
       "max        0.919482\n",
       "Name: risk, dtype: float64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf[\"risk\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "national-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1358441959384354816</td>\n",
       "      <td>@IsaiBCortez Heck yeah, bro.\\n\\nThank God ever...</td>\n",
       "      <td>0.919482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>1341018195709161473</td>\n",
       "      <td>@paul__132 Most code comments and documentatio...</td>\n",
       "      <td>0.892314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>1334353023678574592</td>\n",
       "      <td>@MilesNextDoor bro u don't know how much i suc...</td>\n",
       "      <td>0.870974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>1335728924018425856</td>\n",
       "      <td>@chachovaladez Die Hard.\\n\\nJust kidding, it’s...</td>\n",
       "      <td>0.847634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>1335019222057897984</td>\n",
       "      <td>@mikulaja Also, that boss was obviously a jerk...</td>\n",
       "      <td>0.811857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1363085498164514818</td>\n",
       "      <td>@estebanuribe @EuniceCancino @Eliana_Murillo @...</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1363085233944363008</td>\n",
       "      <td>@EuniceCancino @Eliana_Murillo @estebanuribe @...</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1362967936508387332</td>\n",
       "      <td>@EuniceCancino @Eliana_Murillo @estebanuribe @...</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1362965700701167617</td>\n",
       "      <td>@Eliana_Murillo @estebanuribe @EuniceCancino @...</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1378516199642779650</td>\n",
       "      <td>@IsaiBCortez @cisco_iz @Eliana_Murillo @Buildw...</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>797 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                              tweet  \\\n",
       "270  1358441959384354816  @IsaiBCortez Heck yeah, bro.\\n\\nThank God ever...   \n",
       "658  1341018195709161473  @paul__132 Most code comments and documentatio...   \n",
       "753  1334353023678574592  @MilesNextDoor bro u don't know how much i suc...   \n",
       "737  1335728924018425856  @chachovaladez Die Hard.\\n\\nJust kidding, it’s...   \n",
       "745  1335019222057897984  @mikulaja Also, that boss was obviously a jerk...   \n",
       "..                   ...                                                ...   \n",
       "172  1363085498164514818  @estebanuribe @EuniceCancino @Eliana_Murillo @...   \n",
       "173  1363085233944363008  @EuniceCancino @Eliana_Murillo @estebanuribe @...   \n",
       "174  1362967936508387332  @EuniceCancino @Eliana_Murillo @estebanuribe @...   \n",
       "175  1362965700701167617  @Eliana_Murillo @estebanuribe @EuniceCancino @...   \n",
       "0    1378516199642779650  @IsaiBCortez @cisco_iz @Eliana_Murillo @Buildw...   \n",
       "\n",
       "         risk  \n",
       "270  0.919482  \n",
       "658  0.892314  \n",
       "753  0.870974  \n",
       "737  0.847634  \n",
       "745  0.811857  \n",
       "..        ...  \n",
       "172 -1.000000  \n",
       "173 -1.000000  \n",
       "174 -1.000000  \n",
       "175 -1.000000  \n",
       "0   -1.000000  \n",
       "\n",
       "[797 rows x 3 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.sort_values(by=\"risk\", ascending=False)[[\"tweet_id\", \"tweet\", \"risk\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-christopher",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
